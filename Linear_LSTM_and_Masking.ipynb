{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHAxCQocTh8pdau6B6ZQF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxtost10/Playground-vs/blob/main/Linear_LSTM_and_Masking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8iQwHGWdT5JC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch = torch.rand(1, 4, 2)\n",
        "x_batch.shape"
      ],
      "metadata": {
        "id": "jUFT9_EzsmNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d2c25e-4aec-4461-9aad-aaea5b091dcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(x_batch.shape[0], 3, x_batch.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErrUrHX9WF3O",
        "outputId": "93c50cf7-bb22-49b9-bc8d-81831e683226"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ll = torch.nn.Linear(8, 1)"
      ],
      "metadata": {
        "id": "9czQ24gUvdnJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Like this we can build the tensor but it will not be possible to use it with autograd"
      ],
      "metadata": {
        "id": "e67ADcrP3Ami"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x_batch = torch.rand(1, 4, 2)\n",
        "\n",
        "T = x_batch.shape[1]\n",
        "results = []                    # a Python list\n",
        "\n",
        "for n in range(T + 1):\n",
        "    # copy and zero-out positions [n:] along dim=1\n",
        "    masked = x_batch.clone()\n",
        "    masked[:, n:, :] = 0\n",
        "\n",
        "    # flatten and evaluate ll\n",
        "    val = ll(masked.view(-1))\n",
        "    print(val)\n",
        "\n",
        "    results.append(val)\n",
        "\n",
        "# stack into a 1D tensor\n",
        "output = torch.tensor(results)\n",
        "print(\"output shape:\", output.shape)   # torch.Size([25])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbBRzMz2TS2u",
        "outputId": "689ebcb5-5840-4a69-cd00-74b21b2c7a77"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0483], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0707], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0354], grad_fn=<ViewBackward0>)\n",
            "tensor([0.0631], grad_fn=<ViewBackward0>)\n",
            "tensor([0.1893], grad_fn=<ViewBackward0>)\n",
            "output shape: torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nach dem Ausführen des Codes\n",
        "output.sum().backward()\n",
        "print(\"x_batch.grad:\", x_batch.grad)  # Gibt RuntimeError :("
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "y3YaERLa53NC",
        "outputId": "d2cea611-2eb6-4034-f144-8fd6251ae925"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-8aeaeabc4c97>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Nach dem Ausführen des Codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_batch.grad:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sollte nicht None sein, wenn differenzierbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crash course torch masking"
      ],
      "metadata": {
        "id": "AAwstcyb1Vbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Beispiel-Daten: Batch von 3 Sequenzen je Länge 5\n",
        "x = torch.arange(15).view(3,5)\n",
        "# x = tensor([[ 0,  1,  2,  3,  4],\n",
        "#             [ 5,  6,  7,  8,  9],\n",
        "#             [10, 11, 12, 13, 14]])\n",
        "\n",
        "# Maske: nur erste 3 Token jeder Sequenz behalten\n",
        "mask = torch.arange(5) < 3\n",
        "mask = mask.repeat(3, 1)\n",
        "print(mask)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s_JQ7cv1C1y",
        "outputId": "0ecfe501-4dfa-4b90-d637-baca21d8aed1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True,  True,  True, False, False],\n",
            "        [ True,  True,  True, False, False],\n",
            "        [ True,  True,  True, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ergebnis: maskiert (gefiltert) nur die True-Positionen,\n",
        "# liefert flach die Werte [0,1,2, 5,6,7, 10,11,12]\n",
        "selected = x[mask].view(3, -1)\n",
        "print(selected)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68gLGml61bDV",
        "outputId": "67c4ab49-9f6b-4ce1-fe35-75a24311fa9d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2],\n",
              "        [ 5,  6,  7],\n",
              "        [10, 11, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = mask.float()\n",
        "print(x*mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2E5SFJs3VaA",
        "outputId": "2a69327d-0a0a-4a7a-e5bf-eef7c61b312e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  2.,  0.,  0.],\n",
            "        [ 5.,  6.,  7.,  0.,  0.],\n",
            "        [10., 11., 12.,  0.,  0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = mask == 1\n",
        "x.masked_fill(~mask, 111)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN1EFj8Y3owZ",
        "outputId": "5897c3bb-a4a9-408c-97bb-db38d8389dee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   1,   2, 111, 111],\n",
              "        [  5,   6,   7, 111, 111],\n",
              "        [ 10,  11,  12, 111, 111]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With these tools we can now build a differentiable tensor"
      ],
      "metadata": {
        "id": "ms9FLCMn3KPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Beispiel-Batch mit requires_grad, damit x_batch.grad später nicht None ist\n",
        "x_batch = torch.rand(1, 4, 2, requires_grad=True)\n",
        "\n",
        "T = x_batch.shape[1]\n",
        "results = []  # Liste für deine ll()-Rückgaben, jeweils 0-dim Tensoren\n",
        "\n",
        "for n in range(T + 1):\n",
        "    # Baue eine Maske: für jede Zeile ok, für Spalten ≥ n nullen\n",
        "    # Das ist fully differentiable\n",
        "    mask = (torch.arange(T)\n",
        "        .unsqueeze(0)   # Form (1, T)\n",
        "        .lt(n)          # True für Spalten < n, sonst False\n",
        "    ).unsqueeze(-1).float()        # in FloatTensor: 1.0 oder 0.0\n",
        "    masked = x_batch * mask  # Form (8, T, 3)\n",
        "\n",
        "    # ll liefert einen 0-dim Tensor, der ins Gradient-Graph eingebunden ist\n",
        "    val = ll(masked.view(-1))\n",
        "    print(val)\n",
        "    results.append(val)\n",
        "\n",
        "# Hier verbinden wir alle 0-dim-Tensoren zu einem 1-dim-Tensor\n",
        "output = torch.stack(results)  # shape: (T+1,)\n",
        "\n",
        "# Jetzt kann man problemlos loss = output.sum(); loss.backward()\n",
        "print(\"Output shape:\", output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31G49kV3JoI",
        "outputId": "198223b9-ce96-4bb8-d85c-c55816e2a907"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0483], grad_fn=<ViewBackward0>)\n",
            "tensor([0.0205], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0024], grad_fn=<ViewBackward0>)\n",
            "tensor([0.1152], grad_fn=<ViewBackward0>)\n",
            "tensor([0.3323], grad_fn=<ViewBackward0>)\n",
            "Output shape: torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nach dem Ausführen des Codes\n",
        "output.sum().backward()\n",
        "print(\"x_batch.grad:\", x_batch.grad)  # Sollte nicht None sein, wenn differenzierbar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ-VAEpj1eMl",
        "outputId": "3ed36936-061f-42b8-b86d-c680a65cebdd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_batch.grad: tensor([[[-0.6544, -0.1412],\n",
            "         [ 0.6882, -0.6431],\n",
            "         [-0.1688,  0.5499],\n",
            "         [ 0.0247,  0.2187]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-HLjv0P5xuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}